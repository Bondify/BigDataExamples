Big data, macrodatos,[1]​ datos masivos, inteligencia de datos o datos a gran escala es un concepto que hace referencia a un conjuntos de datos tan grandes que aplicaciones informáticas tradicionales de procesamiento de datos no son suficientes para tratar con ellos y 

los procedimientos usados para encontrar patrones repetitivos dentro de esos datos. Los textos científicos en español con frecuencia se usa directamente el término en inglés big data, tal como aparece en el ensayo de Viktor Schönberger: La revolución de los datos masivos.[2]​

La disciplina dedicada a los datos masivos se enmarca en el sector de las tecnologías de la información y la comunicación. Esta disciplina se ocupa de todas las actividades relacionadas con los sistemas que manipulan grandes conjuntos de datos. Las dificultades más habituales vinculadas a la gestión de estas cantidades de datos se centran en la recolección y el almacenamiento,[3]​ búsqueda, compartición, análisis,[4]​ y visualización. La tendencia a manipular eno

rmes cantidades de datos se debe a la necesidad en muchos casos de incluir dicha información para la creación de informes estadísticos y modelos predictivos utilizados en diversas materias, como los análisis de negocio, publicitarios, los datos de enfermedades infecciosas, el espionaje y seguimiento a la población o la lucha contra el crimen organizado.[5]​

El límite superior de procesamiento ha ido creciendo a lo largo de los años. Se estima que el mundo almacenó unos 5 zettabytes en 2014. Si se pone esta información en libros, convirtiendo las imágenes y todo eso a su equivalente en letras, se podría hacer 4500 pilas de libros que lleguen hasta el sol.[6]​ Los científicos con cierta regularidad encuentran límites en el análisis debido a la gran cantidad de datos en ciertas áreas, tales como la meteorología, la g

enómica,[7]​ la conectómica, las complejas simulaciones de procesos físicos[8]​ y las investigaciones relacionadas con los procesos biológicos y ambientales,[9]​ Las limitaciones también afectan a los motores de búsqueda en internet, a los sistemas finanzas y a la informática de negocios. Los data sets crecen en volumen debido en parte a la recolección masiva de información procedente de los sensores inalámbricos y los dispositivos móviles (por ejemplo las VANET), 

el constante crecimiento de los históricos de aplicaciones (por ejemplo de los registros), cámaras (sistemas de teledetección), micrófonos, lectores de identificación por radiofrecuencia.[10]​[11]​ La capacidad tecnológica per cápita a nivel mundial para almacenar datos se dobla aproximadamente cada cuarenta meses desde los años 1980.[12]​ Se estima que en 2012 cada día fueron creados cerca de 2.5 trillones de bytes de datos.[13]​